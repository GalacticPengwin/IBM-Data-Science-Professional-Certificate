{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tuning - LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For LR model, we will tune 3 parameters: penalty, C and solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # parameter tuning\n",
    "# from sklearn.model_selection import GridSearchCV \n",
    "\n",
    "# # create parameter grid\n",
    "# param_grid = {'penalty': ['l1', 'l2'],\n",
    "#               'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "#               'solver': ['newton-cg', 'lbfgs', 'liblinear']\n",
    "#              }\n",
    "\n",
    "# lr1 = GridSearchCV(estimator = LogisticRegression(),\n",
    "#                    param_grid = param_grid, \n",
    "#                    scoring='f1', \n",
    "#                    n_jobs=-1\n",
    "#                   )\n",
    "\n",
    "# lr1.fit(X_tr_sc_rebal, y_train_rebal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scoremodel(model):\n",
    "    \n",
    "#     print(model.best_params_)\n",
    "#     print(model.best_score_)\n",
    "\n",
    "#     yhat = model.predict(X_te_sc)\n",
    "#     cr = metrics.classification_report(y_test,yhat)\n",
    "#     print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoremodel(lr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is no improvement in the LR model, perhaps signifying that the model may not be appropriate for the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tuning - GBC\n",
    "\n",
    "For GBC model, we have to tune a series of parameters. As a baseline, we set a series of parameter values below:\n",
    "\n",
    "* **learning_rate** = 0.1 : Default rate is 0.1. For baseline model, we will maintain this\n",
    "* **n_estimators** : We will start tuning this parameter from 10-100 \n",
    "* **max_depth** = 8 : Will be adjusted subsequently\n",
    "* **min_samples_split** = 500 : ~0.5-1% of total training set entries\n",
    "* **min_samples_leaf** = 50 : Chosen randomly, used to prevent overfitting\n",
    "* **subsample** = 0.8 : This is a commonly used used start value\n",
    "* **max_features** = ‘sqrt’ : Chosen as a general thumb-rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create parameter grid to tune n_estimators\n",
    "param_grid = {'n_estimators': range(10,101,10)}\n",
    "\n",
    "# gbc1 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1,\n",
    "#                                                            min_samples_split=500,\n",
    "#                                                            min_samples_leaf=50, \n",
    "#                                                            max_depth=8,\n",
    "#                                                            max_features='sqrt',\n",
    "#                                                            subsample=0.8,\n",
    "#                                                            random_state=42),\n",
    "#                     param_grid = param_grid,\n",
    "#                     scoring='f1',\n",
    "#                     n_jobs=-1,\n",
    "#                     cv=5\n",
    "#                     )\n",
    "\n",
    "# gbc1.fit(X_tr_sc_rebal, y_train_rebal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoremodel(gbc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tune max_depth and min_samples_split\n",
    "# param_grid = {'max_depth': range(5, 16, 2),\n",
    "#               'min_samples_split': range(200, 1001, 200)\n",
    "#              }\n",
    "\n",
    "# gbc2 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1,\n",
    "#                                                            n_estimators=20,\n",
    "#                                                            min_samples_leaf=50, \n",
    "#                                                            max_features='sqrt',\n",
    "#                                                            subsample=0.8,\n",
    "#                                                            random_state=42),\n",
    "#                     param_grid = param_grid,\n",
    "#                     scoring='f1',\n",
    "#                     n_jobs=-1,\n",
    "#                     cv=5\n",
    "#                     )\n",
    "\n",
    "# gbc2.fit(X_tr_sc_rebal, y_train_rebal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoremodel(gbc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tune min_sample_leaf and min_samples_split\n",
    "# param_grid = {'min_samples_leaf': range(30,71,10),\n",
    "#               'min_samples_split': range(1000, 2001, 200)\n",
    "#              }\n",
    "\n",
    "# gbc3 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1,\n",
    "#                                                            n_estimators=20,\n",
    "#                                                            max_depth=5,\n",
    "#                                                            max_features='sqrt',\n",
    "#                                                            subsample=0.8,\n",
    "#                                                            random_state=42),\n",
    "#                     param_grid = param_grid,\n",
    "#                     scoring='f1',\n",
    "#                     n_jobs=-1\n",
    "#                     )\n",
    "\n",
    "# gbc3.fit(X_tr_sc_rebal, y_train_rebal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoremodel(gbc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tune min_sample_leaf and min_samples_split\n",
    "# param_grid = {'max_features': range(5,19,2)}\n",
    "\n",
    "# gbc4 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1,\n",
    "#                                                            n_estimators=20,\n",
    "#                                                            max_depth=5,\n",
    "#                                                            min_samples_leaf=30,\n",
    "#                                                            min_samples_split=1000,\n",
    "#                                                            subsample=0.8,\n",
    "#                                                            random_state=42),\n",
    "#                     param_grid = param_grid,\n",
    "#                     scoring='f1',\n",
    "#                     n_jobs=-1\n",
    "#                     )\n",
    "\n",
    "# gbc4.fit(X_tr_sc_rebal, y_train_rebal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoremodel(gbc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tune min_sample_leaf and min_samples_split\n",
    "# param_grid = {'subsample': [0.6,0.7,0.75,0.8,0.85,0.9]}\n",
    "\n",
    "# gbc5 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1,\n",
    "#                                                            n_estimators=20,\n",
    "#                                                            max_depth=5,\n",
    "#                                                            min_samples_leaf=30,\n",
    "#                                                            min_samples_split=1000,\n",
    "#                                                            max_features=15,\n",
    "#                                                            random_state=42),\n",
    "#                     param_grid = param_grid,\n",
    "#                     scoring='f1',\n",
    "#                     n_jobs=-1\n",
    "#                     )\n",
    "\n",
    "# gbc5.fit(X_tr_sc_rebal, y_train_rebal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoremodel(gbc5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbc6 = GradientBoostingClassifier(learning_rate=0.05,\n",
    "#                                   n_estimators=40,\n",
    "#                                   max_depth=5,\n",
    "#                                   min_samples_leaf=30,\n",
    "#                                   min_samples_split=1000,\n",
    "#                                   max_features=15,\n",
    "#                                   subsample=0.6,\n",
    "#                                   random_state=42)\n",
    "                    \n",
    "\n",
    "# gbc6.fit(X_tr_sc_rebal, y_train_rebal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yhat = gbc6.predict(X_te_sc)\n",
    "# cr = metrics.classification_report(y_test,yhat)\n",
    "# print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbc7 = GradientBoostingClassifier(learning_rate=0.005, n_estimators=1200,max_depth=7, min_samples_split=200, min_samples_leaf=40, subsample=0.80, random_state=42, max_features=19)\n",
    "\n",
    "# gbc7.fit(X_tr_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yhat = gbc7.predict(X_te_sc)\n",
    "# cr = metrics.classification_report(y_test,yhat)\n",
    "# print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
